{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "092d0513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "sns.color_palette('Set2')\n",
    "dlsu_green = \"#117a65ff\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138c602f",
   "metadata": {},
   "source": [
    "## Income classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65428ab0",
   "metadata": {},
   "source": [
    "For this notebook you are to develop a machine learning model that will be bale to classify if an individual has a salary above 50k or less than 50k using demographic and occupation data. \n",
    "\n",
    "age: continuous. <br>\n",
    "workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "fnlwgt: continuous. <br>\n",
    "education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool. <br>\n",
    "education-num: continuous. <br>\n",
    "marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse. <br>\n",
    "occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces. <br>\n",
    "relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried. <br>\n",
    "race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black. <br>\n",
    "sex: Female, Male. <br>\n",
    "capital-gain: continuous. <br>\n",
    "capital-loss: continuous. <br>\n",
    "hours-per-week: continuous. <br>\n",
    "native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands. <br>\n",
    "class: >50K, <=50K **target variable**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69566b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"data/adult.csv\")\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c10afb92-db62-4dc1-98b7-e050031cbe04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   age              48842 non-null  int64 \n",
      " 1   workclass        48842 non-null  object\n",
      " 2   fnlwgt           48842 non-null  int64 \n",
      " 3   education        48842 non-null  object\n",
      " 4   educational-num  48842 non-null  int64 \n",
      " 5   marital-status   48842 non-null  object\n",
      " 6   occupation       48842 non-null  object\n",
      " 7   relationship     48842 non-null  object\n",
      " 8   race             48842 non-null  object\n",
      " 9   gender           48842 non-null  object\n",
      " 10  capital-gain     48842 non-null  int64 \n",
      " 11  capital-loss     48842 non-null  int64 \n",
      " 12  hours-per-week   48842 non-null  int64 \n",
      " 13  native-country   48842 non-null  object\n",
      " 14  income           48842 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8c1ba76-6b0e-4be4-9d9d-0f4d265cc4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                0\n",
       "workclass          0\n",
       "fnlwgt             0\n",
       "education          0\n",
       "educational-num    0\n",
       "marital-status     0\n",
       "occupation         0\n",
       "relationship       0\n",
       "race               0\n",
       "gender             0\n",
       "capital-gain       0\n",
       "capital-loss       0\n",
       "hours-per-week     0\n",
       "native-country     0\n",
       "income             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297256ea-0294-4c27-a714-12067b1be629",
   "metadata": {},
   "source": [
    "# Do some descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a829e592-ac98-4071-be87-eb1978484a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48842.000000</td>\n",
       "      <td>4.884200e+04</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.643585</td>\n",
       "      <td>1.896641e+05</td>\n",
       "      <td>10.078089</td>\n",
       "      <td>1079.067626</td>\n",
       "      <td>87.502314</td>\n",
       "      <td>40.422382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.710510</td>\n",
       "      <td>1.056040e+05</td>\n",
       "      <td>2.570973</td>\n",
       "      <td>7452.019058</td>\n",
       "      <td>403.004552</td>\n",
       "      <td>12.391444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.175505e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.781445e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.376420e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  educational-num  capital-gain  \\\n",
       "count  48842.000000  4.884200e+04     48842.000000  48842.000000   \n",
       "mean      38.643585  1.896641e+05        10.078089   1079.067626   \n",
       "std       13.710510  1.056040e+05         2.570973   7452.019058   \n",
       "min       17.000000  1.228500e+04         1.000000      0.000000   \n",
       "25%       28.000000  1.175505e+05         9.000000      0.000000   \n",
       "50%       37.000000  1.781445e+05        10.000000      0.000000   \n",
       "75%       48.000000  2.376420e+05        12.000000      0.000000   \n",
       "max       90.000000  1.490400e+06        16.000000  99999.000000   \n",
       "\n",
       "       capital-loss  hours-per-week  \n",
       "count  48842.000000    48842.000000  \n",
       "mean      87.502314       40.422382  \n",
       "std      403.004552       12.391444  \n",
       "min        0.000000        1.000000  \n",
       "25%        0.000000       40.000000  \n",
       "50%        0.000000       40.000000  \n",
       "75%        0.000000       45.000000  \n",
       "max     4356.000000       99.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9843e4c7-4cb2-4f49-903e-2ca2431b10e8",
   "metadata": {},
   "source": [
    "## Look into distribution of target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf954506-c4d5-40ae-bd50-2ff08450b3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='income', ylabel='count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=data_df.income)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432b7bc0-5a2c-4053-85c7-cae289bd907b",
   "metadata": {},
   "source": [
    "## Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d07a2821-18e3-42c5-a9af-0836cc967197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python/3.10.4/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0_?</th>\n",
       "      <th>x0_Federal-gov</th>\n",
       "      <th>x0_Local-gov</th>\n",
       "      <th>x0_Never-worked</th>\n",
       "      <th>x0_Private</th>\n",
       "      <th>x0_Self-emp-inc</th>\n",
       "      <th>x0_Self-emp-not-inc</th>\n",
       "      <th>x0_State-gov</th>\n",
       "      <th>x0_Without-pay</th>\n",
       "      <th>x1_10th</th>\n",
       "      <th>...</th>\n",
       "      <th>x7_Portugal</th>\n",
       "      <th>x7_Puerto-Rico</th>\n",
       "      <th>x7_Scotland</th>\n",
       "      <th>x7_South</th>\n",
       "      <th>x7_Taiwan</th>\n",
       "      <th>x7_Thailand</th>\n",
       "      <th>x7_Trinadad&amp;Tobago</th>\n",
       "      <th>x7_United-States</th>\n",
       "      <th>x7_Vietnam</th>\n",
       "      <th>x7_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x0_?  x0_Federal-gov  x0_Local-gov  x0_Never-worked  x0_Private  \\\n",
       "0       0.0             0.0           0.0              0.0         1.0   \n",
       "1       0.0             0.0           0.0              0.0         1.0   \n",
       "2       0.0             0.0           1.0              0.0         0.0   \n",
       "3       0.0             0.0           0.0              0.0         1.0   \n",
       "4       1.0             0.0           0.0              0.0         0.0   \n",
       "...     ...             ...           ...              ...         ...   \n",
       "48837   0.0             0.0           0.0              0.0         1.0   \n",
       "48838   0.0             0.0           0.0              0.0         1.0   \n",
       "48839   0.0             0.0           0.0              0.0         1.0   \n",
       "48840   0.0             0.0           0.0              0.0         1.0   \n",
       "48841   0.0             0.0           0.0              0.0         0.0   \n",
       "\n",
       "       x0_Self-emp-inc  x0_Self-emp-not-inc  x0_State-gov  x0_Without-pay  \\\n",
       "0                  0.0                  0.0           0.0             0.0   \n",
       "1                  0.0                  0.0           0.0             0.0   \n",
       "2                  0.0                  0.0           0.0             0.0   \n",
       "3                  0.0                  0.0           0.0             0.0   \n",
       "4                  0.0                  0.0           0.0             0.0   \n",
       "...                ...                  ...           ...             ...   \n",
       "48837              0.0                  0.0           0.0             0.0   \n",
       "48838              0.0                  0.0           0.0             0.0   \n",
       "48839              0.0                  0.0           0.0             0.0   \n",
       "48840              0.0                  0.0           0.0             0.0   \n",
       "48841              1.0                  0.0           0.0             0.0   \n",
       "\n",
       "       x1_10th  ...  x7_Portugal  x7_Puerto-Rico  x7_Scotland  x7_South  \\\n",
       "0          0.0  ...          0.0             0.0          0.0       0.0   \n",
       "1          0.0  ...          0.0             0.0          0.0       0.0   \n",
       "2          0.0  ...          0.0             0.0          0.0       0.0   \n",
       "3          0.0  ...          0.0             0.0          0.0       0.0   \n",
       "4          0.0  ...          0.0             0.0          0.0       0.0   \n",
       "...        ...  ...          ...             ...          ...       ...   \n",
       "48837      0.0  ...          0.0             0.0          0.0       0.0   \n",
       "48838      0.0  ...          0.0             0.0          0.0       0.0   \n",
       "48839      0.0  ...          0.0             0.0          0.0       0.0   \n",
       "48840      0.0  ...          0.0             0.0          0.0       0.0   \n",
       "48841      0.0  ...          0.0             0.0          0.0       0.0   \n",
       "\n",
       "       x7_Taiwan  x7_Thailand  x7_Trinadad&Tobago  x7_United-States  \\\n",
       "0            0.0          0.0                 0.0               1.0   \n",
       "1            0.0          0.0                 0.0               1.0   \n",
       "2            0.0          0.0                 0.0               1.0   \n",
       "3            0.0          0.0                 0.0               1.0   \n",
       "4            0.0          0.0                 0.0               1.0   \n",
       "...          ...          ...                 ...               ...   \n",
       "48837        0.0          0.0                 0.0               1.0   \n",
       "48838        0.0          0.0                 0.0               1.0   \n",
       "48839        0.0          0.0                 0.0               1.0   \n",
       "48840        0.0          0.0                 0.0               1.0   \n",
       "48841        0.0          0.0                 0.0               1.0   \n",
       "\n",
       "       x7_Vietnam  x7_Yugoslavia  \n",
       "0             0.0            0.0  \n",
       "1             0.0            0.0  \n",
       "2             0.0            0.0  \n",
       "3             0.0            0.0  \n",
       "4             0.0            0.0  \n",
       "...           ...            ...  \n",
       "48837         0.0            0.0  \n",
       "48838         0.0            0.0  \n",
       "48839         0.0            0.0  \n",
       "48840         0.0            0.0  \n",
       "48841         0.0            0.0  \n",
       "\n",
       "[48842 rows x 102 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# introduce onehot encoding for cotegoricaL vaLues\n",
    "model_data = data_df.copy(deep=True)\n",
    "model_data.income = data_df.income.apply(lambda x: 1 if x == '>=50' else 0)\n",
    "cat_cols = model_data.select_dtypes(exclude=np.number).columns.values\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "res = enc.fit_transform(model_data[cat_cols])\n",
    "res_df = pd.DataFrame(res.todense(), columns=enc.get_feature_names())\n",
    "display(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c887d87d-b7b2-49c1-9d9e-85d9d1cf2938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['workclass' 'education' 'marital-status' 'occupation' 'relationship'\n",
      " 'race' 'gender' 'native-country']\n"
     ]
    }
   ],
   "source": [
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6751db9-a20e-41ed-ac4d-95a048e0fad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age     workclass  fnlwgt     education  educational-num  \\\n",
       "0       25       Private  226802          11th                7   \n",
       "1       38       Private   89814       HS-grad                9   \n",
       "2       28     Local-gov  336951    Assoc-acdm               12   \n",
       "3       44       Private  160323  Some-college               10   \n",
       "4       18             ?  103497  Some-college               10   \n",
       "...    ...           ...     ...           ...              ...   \n",
       "48837   27       Private  257302    Assoc-acdm               12   \n",
       "48838   40       Private  154374       HS-grad                9   \n",
       "48839   58       Private  151910       HS-grad                9   \n",
       "48840   22       Private  201490       HS-grad                9   \n",
       "48841   52  Self-emp-inc  287927       HS-grad                9   \n",
       "\n",
       "           marital-status         occupation relationship   race  gender  \\\n",
       "0           Never-married  Machine-op-inspct    Own-child  Black    Male   \n",
       "1      Married-civ-spouse    Farming-fishing      Husband  White    Male   \n",
       "2      Married-civ-spouse    Protective-serv      Husband  White    Male   \n",
       "3      Married-civ-spouse  Machine-op-inspct      Husband  Black    Male   \n",
       "4           Never-married                  ?    Own-child  White  Female   \n",
       "...                   ...                ...          ...    ...     ...   \n",
       "48837  Married-civ-spouse       Tech-support         Wife  White  Female   \n",
       "48838  Married-civ-spouse  Machine-op-inspct      Husband  White    Male   \n",
       "48839             Widowed       Adm-clerical    Unmarried  White  Female   \n",
       "48840       Never-married       Adm-clerical    Own-child  White    Male   \n",
       "48841  Married-civ-spouse    Exec-managerial         Wife  White  Female   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country income  \n",
       "0                 0             0              40  United-States  <=50K  \n",
       "1                 0             0              50  United-States  <=50K  \n",
       "2                 0             0              40  United-States   >50K  \n",
       "3              7688             0              40  United-States   >50K  \n",
       "4                 0             0              30  United-States  <=50K  \n",
       "...             ...           ...             ...            ...    ...  \n",
       "48837             0             0              38  United-States  <=50K  \n",
       "48838             0             0              40  United-States   >50K  \n",
       "48839             0             0              40  United-States  <=50K  \n",
       "48840             0             0              20  United-States  <=50K  \n",
       "48841         15024             0              40  United-States   >50K  \n",
       "\n",
       "[48842 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d139770f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x0_?', 'x0_Federal-gov', 'x0_Local-gov', 'x0_Never-worked',\n",
       "       'x0_Private', 'x0_Self-emp-inc', 'x0_Self-emp-not-inc', 'x0_State-gov',\n",
       "       'x0_Without-pay', 'x1_10th', 'x1_11th', 'x1_12th', 'x1_1st-4th',\n",
       "       'x1_5th-6th', 'x1_7th-8th', 'x1_9th', 'x1_Assoc-acdm', 'x1_Assoc-voc',\n",
       "       'x1_Bachelors', 'x1_Doctorate', 'x1_HS-grad', 'x1_Masters',\n",
       "       'x1_Preschool', 'x1_Prof-school', 'x1_Some-college', 'x2_Divorced',\n",
       "       'x2_Married-AF-spouse', 'x2_Married-civ-spouse',\n",
       "       'x2_Married-spouse-absent', 'x2_Never-married', 'x2_Separated',\n",
       "       'x2_Widowed', 'x3_?', 'x3_Adm-clerical', 'x3_Armed-Forces',\n",
       "       'x3_Craft-repair', 'x3_Exec-managerial', 'x3_Farming-fishing',\n",
       "       'x3_Handlers-cleaners', 'x3_Machine-op-inspct', 'x3_Other-service',\n",
       "       'x3_Priv-house-serv', 'x3_Prof-specialty', 'x3_Protective-serv',\n",
       "       'x3_Sales', 'x3_Tech-support'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.columns[:46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4a9f362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Private', 'Local-gov', '?', 'Self-emp-not-inc', 'Federal-gov',\n",
       "       'State-gov', 'Self-emp-inc', 'Without-pay', 'Never-worked'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.workclass.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ebc773c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python/3.10.4/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0_?</th>\n",
       "      <th>x0_Federal-gov</th>\n",
       "      <th>x0_Local-gov</th>\n",
       "      <th>x0_Never-worked</th>\n",
       "      <th>x0_Private</th>\n",
       "      <th>x0_Self-emp-inc</th>\n",
       "      <th>x0_Self-emp-not-inc</th>\n",
       "      <th>x0_State-gov</th>\n",
       "      <th>x0_Without-pay</th>\n",
       "      <th>x1_10th</th>\n",
       "      <th>...</th>\n",
       "      <th>x7_Portugal</th>\n",
       "      <th>x7_Puerto-Rico</th>\n",
       "      <th>x7_Scotland</th>\n",
       "      <th>x7_South</th>\n",
       "      <th>x7_Taiwan</th>\n",
       "      <th>x7_Thailand</th>\n",
       "      <th>x7_Trinadad&amp;Tobago</th>\n",
       "      <th>x7_United-States</th>\n",
       "      <th>x7_Vietnam</th>\n",
       "      <th>x7_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x0_?  x0_Federal-gov  x0_Local-gov  x0_Never-worked  x0_Private  \\\n",
       "0       0.0             0.0           0.0              0.0         1.0   \n",
       "1       0.0             0.0           0.0              0.0         1.0   \n",
       "2       0.0             0.0           1.0              0.0         0.0   \n",
       "3       0.0             0.0           0.0              0.0         1.0   \n",
       "4       1.0             0.0           0.0              0.0         0.0   \n",
       "...     ...             ...           ...              ...         ...   \n",
       "48837   0.0             0.0           0.0              0.0         1.0   \n",
       "48838   0.0             0.0           0.0              0.0         1.0   \n",
       "48839   0.0             0.0           0.0              0.0         1.0   \n",
       "48840   0.0             0.0           0.0              0.0         1.0   \n",
       "48841   0.0             0.0           0.0              0.0         0.0   \n",
       "\n",
       "       x0_Self-emp-inc  x0_Self-emp-not-inc  x0_State-gov  x0_Without-pay  \\\n",
       "0                  0.0                  0.0           0.0             0.0   \n",
       "1                  0.0                  0.0           0.0             0.0   \n",
       "2                  0.0                  0.0           0.0             0.0   \n",
       "3                  0.0                  0.0           0.0             0.0   \n",
       "4                  0.0                  0.0           0.0             0.0   \n",
       "...                ...                  ...           ...             ...   \n",
       "48837              0.0                  0.0           0.0             0.0   \n",
       "48838              0.0                  0.0           0.0             0.0   \n",
       "48839              0.0                  0.0           0.0             0.0   \n",
       "48840              0.0                  0.0           0.0             0.0   \n",
       "48841              1.0                  0.0           0.0             0.0   \n",
       "\n",
       "       x1_10th  ...  x7_Portugal  x7_Puerto-Rico  x7_Scotland  x7_South  \\\n",
       "0          0.0  ...          0.0             0.0          0.0       0.0   \n",
       "1          0.0  ...          0.0             0.0          0.0       0.0   \n",
       "2          0.0  ...          0.0             0.0          0.0       0.0   \n",
       "3          0.0  ...          0.0             0.0          0.0       0.0   \n",
       "4          0.0  ...          0.0             0.0          0.0       0.0   \n",
       "...        ...  ...          ...             ...          ...       ...   \n",
       "48837      0.0  ...          0.0             0.0          0.0       0.0   \n",
       "48838      0.0  ...          0.0             0.0          0.0       0.0   \n",
       "48839      0.0  ...          0.0             0.0          0.0       0.0   \n",
       "48840      0.0  ...          0.0             0.0          0.0       0.0   \n",
       "48841      0.0  ...          0.0             0.0          0.0       0.0   \n",
       "\n",
       "       x7_Taiwan  x7_Thailand  x7_Trinadad&Tobago  x7_United-States  \\\n",
       "0            0.0          0.0                 0.0               1.0   \n",
       "1            0.0          0.0                 0.0               1.0   \n",
       "2            0.0          0.0                 0.0               1.0   \n",
       "3            0.0          0.0                 0.0               1.0   \n",
       "4            0.0          0.0                 0.0               1.0   \n",
       "...          ...          ...                 ...               ...   \n",
       "48837        0.0          0.0                 0.0               1.0   \n",
       "48838        0.0          0.0                 0.0               1.0   \n",
       "48839        0.0          0.0                 0.0               1.0   \n",
       "48840        0.0          0.0                 0.0               1.0   \n",
       "48841        0.0          0.0                 0.0               1.0   \n",
       "\n",
       "       x7_Vietnam  x7_Yugoslavia  \n",
       "0             0.0            0.0  \n",
       "1             0.0            0.0  \n",
       "2             0.0            0.0  \n",
       "3             0.0            0.0  \n",
       "4             0.0            0.0  \n",
       "...           ...            ...  \n",
       "48837         0.0            0.0  \n",
       "48838         0.0            0.0  \n",
       "48839         0.0            0.0  \n",
       "48840         0.0            0.0  \n",
       "48841         0.0            0.0  \n",
       "\n",
       "[48842 rows x 102 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>226802</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>89814</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>336951</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>160323</td>\n",
       "      <td>10</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>103497</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  educational-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0   25  226802                7             0             0              40   \n",
       "1   38   89814                9             0             0              50   \n",
       "2   28  336951               12             0             0              40   \n",
       "3   44  160323               10          7688             0              40   \n",
       "4   18  103497               10             0             0              30   \n",
       "\n",
       "   income  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>x0_?</th>\n",
       "      <th>x0_Federal-gov</th>\n",
       "      <th>x0_Local-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>x7_Portugal</th>\n",
       "      <th>x7_Puerto-Rico</th>\n",
       "      <th>x7_Scotland</th>\n",
       "      <th>x7_South</th>\n",
       "      <th>x7_Taiwan</th>\n",
       "      <th>x7_Thailand</th>\n",
       "      <th>x7_Trinadad&amp;Tobago</th>\n",
       "      <th>x7_United-States</th>\n",
       "      <th>x7_Vietnam</th>\n",
       "      <th>x7_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>226802</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>89814</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>336951</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>160323</td>\n",
       "      <td>10</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>103497</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  educational-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0   25  226802                7             0             0              40   \n",
       "1   38   89814                9             0             0              50   \n",
       "2   28  336951               12             0             0              40   \n",
       "3   44  160323               10          7688             0              40   \n",
       "4   18  103497               10             0             0              30   \n",
       "\n",
       "   income  x0_?  x0_Federal-gov  x0_Local-gov  ...  x7_Portugal  \\\n",
       "0       0   0.0             0.0           0.0  ...          0.0   \n",
       "1       0   0.0             0.0           0.0  ...          0.0   \n",
       "2       0   0.0             0.0           1.0  ...          0.0   \n",
       "3       0   0.0             0.0           0.0  ...          0.0   \n",
       "4       0   1.0             0.0           0.0  ...          0.0   \n",
       "\n",
       "   x7_Puerto-Rico  x7_Scotland  x7_South  x7_Taiwan  x7_Thailand  \\\n",
       "0             0.0          0.0       0.0        0.0          0.0   \n",
       "1             0.0          0.0       0.0        0.0          0.0   \n",
       "2             0.0          0.0       0.0        0.0          0.0   \n",
       "3             0.0          0.0       0.0        0.0          0.0   \n",
       "4             0.0          0.0       0.0        0.0          0.0   \n",
       "\n",
       "   x7_Trinadad&Tobago  x7_United-States  x7_Vietnam  x7_Yugoslavia  \n",
       "0                 0.0               1.0         0.0            0.0  \n",
       "1                 0.0               1.0         0.0            0.0  \n",
       "2                 0.0               1.0         0.0            0.0  \n",
       "3                 0.0               1.0         0.0            0.0  \n",
       "4                 0.0               1.0         0.0            0.0  \n",
       "\n",
       "[5 rows x 109 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_data = data_df.copy(deep=True)\n",
    "model_data.income = data_df.income.apply(lambda x: 1 if x == '>=50k' else 0)\n",
    "cat_cols = model_data.select_dtypes(exclude=np.number).columns.values\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "res = enc.fit_transform(model_data[cat_cols])\n",
    "res_df = pd.DataFrame(res.todense(), columns=enc.get_feature_names())\n",
    "display(res_df)\n",
    "\n",
    "model_data.drop(cat_cols, axis=1, inplace=True)\n",
    "display(model_data.head())\n",
    "model_data = pd.concat([model_data, res_df], axis=1)\n",
    "display(model_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19b8f68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>x0_?</th>\n",
       "      <th>x0_Federal-gov</th>\n",
       "      <th>x0_Local-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>x7_Portugal</th>\n",
       "      <th>x7_Puerto-Rico</th>\n",
       "      <th>x7_Scotland</th>\n",
       "      <th>x7_South</th>\n",
       "      <th>x7_Taiwan</th>\n",
       "      <th>x7_Thailand</th>\n",
       "      <th>x7_Trinadad&amp;Tobago</th>\n",
       "      <th>x7_United-States</th>\n",
       "      <th>x7_Vietnam</th>\n",
       "      <th>x7_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>226802</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>89814</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>336951</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>160323</td>\n",
       "      <td>10</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>103497</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>27</td>\n",
       "      <td>257302</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>40</td>\n",
       "      <td>154374</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>58</td>\n",
       "      <td>151910</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>22</td>\n",
       "      <td>201490</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>52</td>\n",
       "      <td>287927</td>\n",
       "      <td>9</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  fnlwgt  educational-num  capital-gain  capital-loss  \\\n",
       "0       25  226802                7             0             0   \n",
       "1       38   89814                9             0             0   \n",
       "2       28  336951               12             0             0   \n",
       "3       44  160323               10          7688             0   \n",
       "4       18  103497               10             0             0   \n",
       "...    ...     ...              ...           ...           ...   \n",
       "48837   27  257302               12             0             0   \n",
       "48838   40  154374                9             0             0   \n",
       "48839   58  151910                9             0             0   \n",
       "48840   22  201490                9             0             0   \n",
       "48841   52  287927                9         15024             0   \n",
       "\n",
       "       hours-per-week  income  x0_?  x0_Federal-gov  x0_Local-gov  ...  \\\n",
       "0                  40       0   0.0             0.0           0.0  ...   \n",
       "1                  50       0   0.0             0.0           0.0  ...   \n",
       "2                  40       0   0.0             0.0           1.0  ...   \n",
       "3                  40       0   0.0             0.0           0.0  ...   \n",
       "4                  30       0   1.0             0.0           0.0  ...   \n",
       "...               ...     ...   ...             ...           ...  ...   \n",
       "48837              38       0   0.0             0.0           0.0  ...   \n",
       "48838              40       0   0.0             0.0           0.0  ...   \n",
       "48839              40       0   0.0             0.0           0.0  ...   \n",
       "48840              20       0   0.0             0.0           0.0  ...   \n",
       "48841              40       0   0.0             0.0           0.0  ...   \n",
       "\n",
       "       x7_Portugal  x7_Puerto-Rico  x7_Scotland  x7_South  x7_Taiwan  \\\n",
       "0              0.0             0.0          0.0       0.0        0.0   \n",
       "1              0.0             0.0          0.0       0.0        0.0   \n",
       "2              0.0             0.0          0.0       0.0        0.0   \n",
       "3              0.0             0.0          0.0       0.0        0.0   \n",
       "4              0.0             0.0          0.0       0.0        0.0   \n",
       "...            ...             ...          ...       ...        ...   \n",
       "48837          0.0             0.0          0.0       0.0        0.0   \n",
       "48838          0.0             0.0          0.0       0.0        0.0   \n",
       "48839          0.0             0.0          0.0       0.0        0.0   \n",
       "48840          0.0             0.0          0.0       0.0        0.0   \n",
       "48841          0.0             0.0          0.0       0.0        0.0   \n",
       "\n",
       "       x7_Thailand  x7_Trinadad&Tobago  x7_United-States  x7_Vietnam  \\\n",
       "0              0.0                 0.0               1.0         0.0   \n",
       "1              0.0                 0.0               1.0         0.0   \n",
       "2              0.0                 0.0               1.0         0.0   \n",
       "3              0.0                 0.0               1.0         0.0   \n",
       "4              0.0                 0.0               1.0         0.0   \n",
       "...            ...                 ...               ...         ...   \n",
       "48837          0.0                 0.0               1.0         0.0   \n",
       "48838          0.0                 0.0               1.0         0.0   \n",
       "48839          0.0                 0.0               1.0         0.0   \n",
       "48840          0.0                 0.0               1.0         0.0   \n",
       "48841          0.0                 0.0               1.0         0.0   \n",
       "\n",
       "       x7_Yugoslavia  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4                0.0  \n",
       "...              ...  \n",
       "48837            0.0  \n",
       "48838            0.0  \n",
       "48839            0.0  \n",
       "48840            0.0  \n",
       "48841            0.0  \n",
       "\n",
       "[48842 rows x 109 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d2162a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python/3.10.4/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0_?</th>\n",
       "      <th>x0_Federal-gov</th>\n",
       "      <th>x0_Local-gov</th>\n",
       "      <th>x0_Never-worked</th>\n",
       "      <th>x0_Private</th>\n",
       "      <th>x0_Self-emp-inc</th>\n",
       "      <th>x0_Self-emp-not-inc</th>\n",
       "      <th>x0_State-gov</th>\n",
       "      <th>x0_Without-pay</th>\n",
       "      <th>x1_10th</th>\n",
       "      <th>...</th>\n",
       "      <th>x7_Portugal</th>\n",
       "      <th>x7_Puerto-Rico</th>\n",
       "      <th>x7_Scotland</th>\n",
       "      <th>x7_South</th>\n",
       "      <th>x7_Taiwan</th>\n",
       "      <th>x7_Thailand</th>\n",
       "      <th>x7_Trinadad&amp;Tobago</th>\n",
       "      <th>x7_United-States</th>\n",
       "      <th>x7_Vietnam</th>\n",
       "      <th>x7_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x0_?  x0_Federal-gov  x0_Local-gov  x0_Never-worked  x0_Private  \\\n",
       "0       0.0             0.0           0.0              0.0         1.0   \n",
       "1       0.0             0.0           0.0              0.0         1.0   \n",
       "2       0.0             0.0           1.0              0.0         0.0   \n",
       "3       0.0             0.0           0.0              0.0         1.0   \n",
       "4       1.0             0.0           0.0              0.0         0.0   \n",
       "...     ...             ...           ...              ...         ...   \n",
       "48837   0.0             0.0           0.0              0.0         1.0   \n",
       "48838   0.0             0.0           0.0              0.0         1.0   \n",
       "48839   0.0             0.0           0.0              0.0         1.0   \n",
       "48840   0.0             0.0           0.0              0.0         1.0   \n",
       "48841   0.0             0.0           0.0              0.0         0.0   \n",
       "\n",
       "       x0_Self-emp-inc  x0_Self-emp-not-inc  x0_State-gov  x0_Without-pay  \\\n",
       "0                  0.0                  0.0           0.0             0.0   \n",
       "1                  0.0                  0.0           0.0             0.0   \n",
       "2                  0.0                  0.0           0.0             0.0   \n",
       "3                  0.0                  0.0           0.0             0.0   \n",
       "4                  0.0                  0.0           0.0             0.0   \n",
       "...                ...                  ...           ...             ...   \n",
       "48837              0.0                  0.0           0.0             0.0   \n",
       "48838              0.0                  0.0           0.0             0.0   \n",
       "48839              0.0                  0.0           0.0             0.0   \n",
       "48840              0.0                  0.0           0.0             0.0   \n",
       "48841              1.0                  0.0           0.0             0.0   \n",
       "\n",
       "       x1_10th  ...  x7_Portugal  x7_Puerto-Rico  x7_Scotland  x7_South  \\\n",
       "0          0.0  ...          0.0             0.0          0.0       0.0   \n",
       "1          0.0  ...          0.0             0.0          0.0       0.0   \n",
       "2          0.0  ...          0.0             0.0          0.0       0.0   \n",
       "3          0.0  ...          0.0             0.0          0.0       0.0   \n",
       "4          0.0  ...          0.0             0.0          0.0       0.0   \n",
       "...        ...  ...          ...             ...          ...       ...   \n",
       "48837      0.0  ...          0.0             0.0          0.0       0.0   \n",
       "48838      0.0  ...          0.0             0.0          0.0       0.0   \n",
       "48839      0.0  ...          0.0             0.0          0.0       0.0   \n",
       "48840      0.0  ...          0.0             0.0          0.0       0.0   \n",
       "48841      0.0  ...          0.0             0.0          0.0       0.0   \n",
       "\n",
       "       x7_Taiwan  x7_Thailand  x7_Trinadad&Tobago  x7_United-States  \\\n",
       "0            0.0          0.0                 0.0               1.0   \n",
       "1            0.0          0.0                 0.0               1.0   \n",
       "2            0.0          0.0                 0.0               1.0   \n",
       "3            0.0          0.0                 0.0               1.0   \n",
       "4            0.0          0.0                 0.0               1.0   \n",
       "...          ...          ...                 ...               ...   \n",
       "48837        0.0          0.0                 0.0               1.0   \n",
       "48838        0.0          0.0                 0.0               1.0   \n",
       "48839        0.0          0.0                 0.0               1.0   \n",
       "48840        0.0          0.0                 0.0               1.0   \n",
       "48841        0.0          0.0                 0.0               1.0   \n",
       "\n",
       "       x7_Vietnam  x7_Yugoslavia  \n",
       "0             0.0            0.0  \n",
       "1             0.0            0.0  \n",
       "2             0.0            0.0  \n",
       "3             0.0            0.0  \n",
       "4             0.0            0.0  \n",
       "...           ...            ...  \n",
       "48837         0.0            0.0  \n",
       "48838         0.0            0.0  \n",
       "48839         0.0            0.0  \n",
       "48840         0.0            0.0  \n",
       "48841         0.0            0.0  \n",
       "\n",
       "[48842 rows x 102 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>226802</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>89814</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>336951</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>160323</td>\n",
       "      <td>10</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>103497</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  educational-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0   25  226802                7             0             0              40   \n",
       "1   38   89814                9             0             0              50   \n",
       "2   28  336951               12             0             0              40   \n",
       "3   44  160323               10          7688             0              40   \n",
       "4   18  103497               10             0             0              30   \n",
       "\n",
       "   income  \n",
       "0       0  \n",
       "1       0  \n",
       "2       1  \n",
       "3       1  \n",
       "4       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>x0_?</th>\n",
       "      <th>x0_Federal-gov</th>\n",
       "      <th>x0_Local-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>x7_Portugal</th>\n",
       "      <th>x7_Puerto-Rico</th>\n",
       "      <th>x7_Scotland</th>\n",
       "      <th>x7_South</th>\n",
       "      <th>x7_Taiwan</th>\n",
       "      <th>x7_Thailand</th>\n",
       "      <th>x7_Trinadad&amp;Tobago</th>\n",
       "      <th>x7_United-States</th>\n",
       "      <th>x7_Vietnam</th>\n",
       "      <th>x7_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>226802</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>89814</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>336951</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>160323</td>\n",
       "      <td>10</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>103497</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  educational-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0   25  226802                7             0             0              40   \n",
       "1   38   89814                9             0             0              50   \n",
       "2   28  336951               12             0             0              40   \n",
       "3   44  160323               10          7688             0              40   \n",
       "4   18  103497               10             0             0              30   \n",
       "\n",
       "   income  x0_?  x0_Federal-gov  x0_Local-gov  ...  x7_Portugal  \\\n",
       "0       0   0.0             0.0           0.0  ...          0.0   \n",
       "1       0   0.0             0.0           0.0  ...          0.0   \n",
       "2       1   0.0             0.0           1.0  ...          0.0   \n",
       "3       1   0.0             0.0           0.0  ...          0.0   \n",
       "4       0   1.0             0.0           0.0  ...          0.0   \n",
       "\n",
       "   x7_Puerto-Rico  x7_Scotland  x7_South  x7_Taiwan  x7_Thailand  \\\n",
       "0             0.0          0.0       0.0        0.0          0.0   \n",
       "1             0.0          0.0       0.0        0.0          0.0   \n",
       "2             0.0          0.0       0.0        0.0          0.0   \n",
       "3             0.0          0.0       0.0        0.0          0.0   \n",
       "4             0.0          0.0       0.0        0.0          0.0   \n",
       "\n",
       "   x7_Trinadad&Tobago  x7_United-States  x7_Vietnam  x7_Yugoslavia  \n",
       "0                 0.0               1.0         0.0            0.0  \n",
       "1                 0.0               1.0         0.0            0.0  \n",
       "2                 0.0               1.0         0.0            0.0  \n",
       "3                 0.0               1.0         0.0            0.0  \n",
       "4                 0.0               1.0         0.0            0.0  \n",
       "\n",
       "[5 rows x 109 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# introduce onehot encoding for categorical values \n",
    "model_data = data_df.copy(deep=True)\n",
    "model_data.income = data_df.income.apply(lambda x: 1 if x == '>50K' else 0)\n",
    "cat_cols = model_data.select_dtypes(exclude=np.number).columns.values\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "res = enc.fit_transform(model_data[cat_cols])\n",
    "res_df = pd.DataFrame(res.todense(), columns=enc.get_feature_names())\n",
    "display(res_df)\n",
    "\n",
    "model_data.drop(cat_cols, axis=1, inplace=True)\n",
    "display(model_data.head())\n",
    "model_data = pd.concat([model_data, res_df], axis=1)\n",
    "display(model_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c1eb25",
   "metadata": {},
   "source": [
    "## Split data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0127c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_data.drop(\"income\", axis=1)\n",
    "y = model_data.income\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90a5f737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    26008\n",
       "1     8181\n",
       "Name: income, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e404a331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11147\n",
       "1     3506\n",
       "Name: income, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10874b9",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef28cc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My program took 472.73930048942566 to run\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": range(100, 150, 10),\n",
    "    \"max_depth\": range(5,50,5),\n",
    "    \"min_samples_split\": np.arange(.1,.6,.1),\n",
    "    \"min_samples_leaf\": np.arange(.1,.6,.1),\n",
    "    \"max_features\": np.arange(0.1, 0.6, .1)\n",
    "}\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf_grid = RandomizedSearchCV(clf, param_grid, n_iter=300, n_jobs=-1)\n",
    "clf_grid.fit(X_train, y_train)\n",
    "# be careful in setting n_jobs=-1 this means it will use all of your processors but will speed up the run of your model\n",
    "print(f\"My program took {time.time() - start_time} to run\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73262d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=0.7079002079002079\n",
      "recall=0.3884768967484313\n",
      "f1=0.5016574585635359\n",
      "accuracy=0.815327919197434\n"
     ]
    }
   ],
   "source": [
    "best_est = clf_grid.best_estimator_\n",
    "\n",
    "y_pred = best_est.predict(X_test)\n",
    "print(f\"precision={precision_score(y_test, y_pred)}\")\n",
    "print(f\"recall={recall_score(y_test, y_pred)}\")\n",
    "print(f\"f1={f1_score(y_test, y_pred)}\")\n",
    "print(f\"accuracy={accuracy_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0970aa",
   "metadata": {},
   "source": [
    "### Model Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4378e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>x2_Married-civ-spouse</td>\n",
       "      <td>0.466251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>x4_Husband</td>\n",
       "      <td>0.234105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>educational-num</td>\n",
       "      <td>0.188702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.041985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>x2_Never-married</td>\n",
       "      <td>0.037469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>x3_Armed-Forces</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>x3_Adm-clerical</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>x3_?</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>x2_Widowed</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>x7_Yugoslavia</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  importance\n",
       "33   x2_Married-civ-spouse    0.466251\n",
       "53              x4_Husband    0.234105\n",
       "2          educational-num    0.188702\n",
       "0                      age    0.041985\n",
       "35        x2_Never-married    0.037469\n",
       "..                     ...         ...\n",
       "40         x3_Armed-Forces    0.000000\n",
       "39         x3_Adm-clerical    0.000000\n",
       "38                    x3_?    0.000000\n",
       "37              x2_Widowed    0.000000\n",
       "107          x7_Yugoslavia    0.000000\n",
       "\n",
       "[108 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_grid.best_estimator_.feature_importances_\n",
    "\n",
    "feat_df = pd.DataFrame()\n",
    "feat_df['feature'] = X_train.columns\n",
    "feat_df['importance'] = clf_grid.best_estimator_.feature_importances_\n",
    "feat_df = feat_df.sort_values('importance', ascending=False)\n",
    "\n",
    "feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62dd535f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 125]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(100, 150, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df7f8c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='importance', ylabel='feature'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeIAAAEGCAYAAAC5PJY3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAArPUlEQVR4nO3deZgdVbn2/286pgkyKYj+cGAUbsJkpBMEkUFARZxA0YhIAEdUjMOL4gDKpAyiiIrAURQQOCIoykFleFEEESE0hLG5nYAj6u8IR0AZkm7S/f5Rq2Wn0+ne3enelXTfn+vKlV1Vq1Y9tRievVatXWtKX18fERERUY+2ugOIiIiYzJKIIyIiapREHBERUaMk4oiIiBolEUdERNToGXUHECuXW265pW/VVVetO4wVyqJFi1hllVXqDmOFkfZYUtpjaZOxTZ544omHOjo61h3sWBJxjMiUKVOYMWNG3WGsULq6utImDdIeS0p7LG0ytklnZ+f9yzqWoemIiIgaJRHHiLS3t9cdwgpnsn2zH07aY0lpj6WtjG2ysKd73OrO0HSMSFtbGxvMm1t3GBERLXX/184dt7rTI46IiKhREnFERESNkogjIiJqlEQcERFRo5ZN1pI0EzgdWBNYDHzB9oVDlL8G2BjYwHZf2fdjYA/bqy9nLD8D3mH7kSbLHwTMsn1ok+XfCGxh+4RRBxkREZNCK2dNPwHMtf17Sc8HOiVdMUwyfATYEfi1pGcB643kgpKmAFNs9w7Y3msU8TfN9qXApeN5jYiImBjGJRFLmg2cBWwHTAVuAubYvhPA9l8l/R1YlyrZLsv3gbcDvwbeDPwI2LJcY3XgJ8CzgWnAEbZ/ImlD4ArgRqAD+KCk/2jY3kvSr6h6uA9JeicwD2gvZT5oe7Gkg4FPl/huAxYt4173BL5Y7vMh27v396CBzwK3AxvZ7pW0GnAPsLHtnoY6tgS+W2JoA94C9ACXA53AtsBdVF9knpC0O3Ay1T+/+cAHbC+SdF/Dfc0CTra9q6RdgFPL5fqAnW3/S9IngLcBqwCX2P78EP8sIiJiHIzLM2Lb86l6hMcBJwHn9SdhAEnbUSWdPw5T1dXAzpKmUiXkxqHshcA+trcFXgl8ufR4ATYFvml7S+D+xm3b/37NmKQZwBxgR9szqYbM95e0HnA0VW/8FcAWgwUnaV3gW8BbbL8EeOuAdngUWADsUna9HriiMQkXhwCnlhhmAQ/0X6LEPQP4J9WXiunA2VRfbLamSsYfGLT1nnYY8KFS/07Ak5JeXdplO2Am0CFp52HqiYiIMTaek7WOAV5FlVhO6t9Zktz3gIP7h4yHsJiqN/x2YFXb9zUcmwJ8UdLtwP8FXgA8rxy73/ZvG8oO3O63O1Uveb6kBWV7Y+BlwDW2H7TdzZJfABptD1xr+14A2/8YpMyFVMkelv4y0e8G4DOSDqd6Jv5k2f9n29eXz+dRfSkQcK/t35X95wDDJdDrga9Imgc8y/ZTwKvLn1uBW4DNqRJzRES00Hg+I14HWJ1q2Hg68LikNYGfAp9dRmIczPeBS4CjBuzfn2pou8N2TxmWnV6OPT6g7MDtflOAc2x/unGnpL0HK1x65p1l81KqYeHhXEr1hWFtqqT/C0n7AP3DwO+xfYGkG4HXAT+T9H7gT1TDyI0Gbg/0FE9/uepvC2yfIOmnwF7A9ZJeQ3Xvx9s+s4l7iIiIcTKePeIzgSOB84ETJbVTJdRzbV88gnquA44H/nPA/rWAv5ck/Epgg1HEeDWwr6TnAkhaW9IGVM+Kd5G0jqRplCFn24ttzyx/Pgf8lmrofKP+8wdewPZjVAn7VOCyUsclDfXcLGlj4E+2v0b13Hubcvr6knYon99BNTpgYENJLy77DwB+VT7fR5XsoXrOTIlrE9t32D6xxLI51XP0d5Vn7Uh6QX87RERE64xLIpY0F+ixfQFwAjCbalh2Z+AgSQvKn5nD1WW7z/bJth8acOh8YJakO4C5VJOgRsT23cARwJVliPsqYD3bf6Pqgd9ANazbtYzzHwTeB/xI0m0sewj7QuCdQxx/G3BnGR7fCuh/qamBD0nqopqUdrrthcDBwEXl3nuBM0r5o4FTJd1MNazf76OS7iz32AP83PaVwAXADaWei4E1lhFfRESMkyl9fcONdkYdyuzvy2xvVXcsjbq6uvr2PP34usOIiGip5V30obOzs7Ojo2PWYMfyZq2IiIga1b4MoqRLgI0G7D7c9hV1xLOiKDPEV6jecEREjL3aE7HtfeqOIZrX29s7rutyRkSsiBb2dDN9Wvu41J2h6RiR7u7uukNY4XR1DTqXb9JKeywp7bG0lbFNxisJQxJxRERErZKIIyIiapREHCPS3j5+wzMrqxkzZtQdwgplPNtjYU8ejcTEU/tkrVi5tLW1scG8uXWHEZNUJgrGRJQecURERI2SiCMiImqURBwREVGjJOKIiIgaJRFHRETUKIl4OUhaU9IDkr4xTLn7JD2nYXtXSZeN8ppL1DVWJB0l6bCxrjciIoaWRLx8jgWurTuIiIhYeeV3xMOQNBs4C9gOmArcBMwBVgGeB1wODLrGZJP1HwU8Zvvksn0n8HrgQeAHwAvLdY+1fWE57ZOSXgs8CbzD9h8kvQE4AmgH/hfY3/b/lPrXBzYuf3/V9tfKtT4LHAj8Hfgz0Dna+4iIiNFJIh6G7fmSLgWOA1YFzgPuBn4BvBPYo8mqfilpcfm8OnDPMOX3BP5q+3UAktZqOPao7a0lzQW+SpW4fw1sb7tP0nuATwL/p5TfHHglsAZgSacD2wBvB2ZS/XtwC0nEEREtl0TcnGOA+cBCYB7wQeBnth+Q1Gwdr7T9EFTPiIHhnsfeAXxZ0onAZbavazj2nw1/n1I+vxC4UNJ6VL3iexvK/9T2ImCRpL9T9eR3Ai6x/USJ6dJmbyQiIsZOnhE3Zx2qXuwawHRgB+BQSfcBJwNzJZ0wyrqfYsl/DtMBbP8O2JYqIR8n6XMNZfoG+fx14Bu2twbe319Psajh82LyBSwiYoWRRNycM4EjgfOBE23vb3t92xtS9WzPtf2pUdZ9H1XCRdK2wEbl8/OBJ2yfB3ypv0wxp+HvG8rntYC/lM8HNnHda4G9Ja0qaQ3gDaOMPyIilkMS8TDKc9ge2xcAJwCzJe02hpf4IbC2pLuAQ4Hflf1bAzdJWgB8nuoZdb9nS7od+AjwsbLvKOAiSZ3AQ8Nd1PYtwIXAbcDPqYbeIyKixab09fUNXyqi6Orq6tvz9OPrDiMmqZVx9aWurq4slTnAZGyTzs7Ozo6OjkF/YZMecURERI0yaWcMSbqR6vfFjQ6wfUcd8URExIoviXgM2X5Z3TGMt97e3pVyeDAmhoU93Uyf1l53GBFjKkPTMSLd3d11h7DC6erqqjuEFcp4tkeScExEScQRERE1SiKOiIioURJxjEh7e4YGB5psP8NY2JPHExFjKZO1YkTa2trYYN7cusOIGmWyXsTYSo84IiKiRknEERERNUoijoiIqFEScURERI0mTSKWdJCkb4xxnXtL2qJh+xhJe4zxNXaVdNlY1hkRESuOzJpePnsDlwF3A9j+XK3RRETESmfCJGJJ7wTmAe3AjcAHgbnAp4FHqNbdXVTKng1cZvvisv2Y7dXL58OBdwK9wM9tf0rSe4H3lbr/ABwAzATeCOwi6QjgLcCR/fVK2h04maqN5wMfsL1I0n3AOcAbgGnAW23fI2k74FRgOvAkcLBtD3PPy6rrKOAx2yeXcncCry+nXQ78Fnh5ieu7wNHAc4H9bd/UVINHRMSYmBBD05JmAHOAHW3PBBZTJdOjgR2BVwBbLLOCp+t5LfAm4GW2XwKcVA79yPbssq8LeLft3wCXAp+wPdP2HxvqmQ6cDcyxvTVVMv5Aw6Uesr0tcDpwWNl3D7CT7ZcCnwO+2OTtD1bXUF4MfBnYvPx5B1X7HAZ8pslrRkTEGJkoPeLdgQ5gviSAVal6fNfYfhBA0oXAZsPUswfwXdtPANj+R9m/laTjgGcBqwNXDFOPgHtt/65snwN8CPhq2f5R+bsTeHP5vBZwjqRNgT6qHm4zBqtrKPf2L8so6S7gatt9ku4ANmzymhERMUYmRI8YmAKcU3qmM20LOGqI8k9R7l1SG9WQ81DOBg4tvdujqYaPl8ei8vdinv4ydCzwS9tbUQ01L3UNSVdIWiDp28PU9e/7K6YPUh6q4fdFDZ8nyheziIiVxkRJxFcD+0p6LoCktYFbqZ7friNpGvDWhvL3UfWgoXrO29/7vAo4WNIzG+oBWAP4W6ln/4Z6/lWODWRgQ0kvLtsHAL8a5h7WAv5SPh80WAHbrylfNN4zTF33AduWe9gW2GiY8hERUZMJkYht3w0cAVwp6XaqhLoeVa/4BuB6qme7/b5FlaRvA3YAHi/1XE713PdmSQt4+pnrkVQTwK6nepbb7/vAJyTdKmmThngWAgcDF5Uh317gjGFu4yTgeEm3svw90x8Ca5eh50OB3w1TPiIiajKlr6+v7hhiJdLV1dW35+nH1x1G1Gi4RR+6urom3YpUQ0l7LG0ytklnZ2dnR0fHrMGOTYgecURExMoqiTgiIqJGmSUbI9Lb25v1aCe5hT3dTJ823A8NIqJZ6RHHiHR3d9cdwgqnq6tr+EITSJJwxNhKIo6IiKhREnFERESNkogjIiJqlEQcI9Le3vrngwt78lw6IiauzJqOEWlra2ODeXNbes3M0o6IiSw94oiIiBolEUdERNQoiTgiIqJGScQRERE1SiKOiIioUWZNTzCSfgy8CJgOnGr7PyS9GzgceAS4DVhk+1BJ61Ktk7x+Of2jtq9vfdQREZNXesQTz7tsdwCzgHmSXgAcCWwP7Ahs3lD2VOAU27OBtwDfbnWwERGTXXrEE888SfuUzy8CDgB+ZfsfAJIuAjYrx/cAtpDUf+6akla3/VgrA46ImMySiCcQSbtSJdcdbD8h6RrgHmDGMk5pA7a3vbA1EUZExEAZmp5Y1gIeLkl4c6rh6NWAXSQ9W9IzqIag+10JfLh/Q9LMVgYbERHpEU80lwOHSOoCDPwW+AvwReAm4B9UPeRHS/l5wGmSbqf6d+Fa4JBWBx0RMZklEU8gthcBrx24X9LNZfb0M4BLgB+X8g8Bc1oaZERELCFD05PDUZIWAHcC91IScURE1C894knA9mF1xxAREYNLjzgiIqJG6RHHiPT29rZ8feCFPd1Mn9be0mtGRLRKesQxIt3d3S2/ZpJwRExkScQRERE1SiKOiIioURJxREREjZKIY0Ta21vzvHZhT+ufRUdE1CGzpmNE2tra2GDe3HG/TqtnZkdE1CU94oiIiBolEUdERNRo2KFpSVOA/YGNbR8jaX3g/7N907hHFxERMcE10yP+JrADsF/Z/hdw2rhFFBERMYk0k4hfZvtDwEIA2w8DK9SrjiTNlHSDpLsk3S5pyKX9JF0j6eaG7VmSrhn3QFtE0vMlXTzCc86WtO94xRQREYNrJhH3SJoK9AFIWhfoHdeoRu4JYK7tLYE9ga9KetYw5zxX0lJr946Hsg5wS+qW9Azbf7WdpBoRsRJoJkF8jWox+edK+gKwL3DEuEY1BEmzgbOA7YCpwE3AHNt3Atj+q6S/A+sCjwxR1ZeAzwI/H1D/VOAEYFdgFeA022dK+j7wPds/LeXOBi6japvByu8KHAs8DGwObNZwjQ2By4HfAi8H5gPfBY4Gngvsb/smSdsBpwLTgSeBg21b0kHAm4HVgamSvjtg+0DgMttbDXE/U4CvA68C/gzkh7sRETUYskcsqY1qIflPAscDfwP2tn1RC2IblO35wKXAccBJwHn9SRigJK924I/DVHUD0C3plQP2vxt41PZsYDbwXkkbARcCbyvXaAd2B346RHmAbYGP2N6Mpb0Y+DJVkt4ceAfwCuAw4DOlzD3ATrZfCnwO+GLD+dsC+9reZRnbw93PPoCALYC5VF8IIiKixYbsEdvulXRaSQT3tCimZhxD1YtcCMzr3ylpPeB7wIG2mxk+P46qd394w75XA9s0PC9dC9iUqud8qqRVqIa/r7X9pKRlle8GbrJ97zKufa/tO0rcdwFX2+6TdAewYUNd50jalOrRwLSG86+y/Y8htoe7n52B/7S9GPirpF8sI86IiBhHzQxNXy3pLcCPbPeNd0BNWodqGHYa1bDt45LWpOqhftb2b5upxPYvJB0HbN+wewrwYdtXDCxfJnS9BpgDfH+o8mVo+vHy+UXAf5VDZ1ANSy9qKN7bsN3L0/9cjgV+aXufMpx9TcM5jw8Ib+D2kPcjaa9llI+IiBZqZrLW+4GLgEWS/inpX5L+Oc5xDedM4EjgfODEMlR8CXCu7RHNFqbqFX+yYfsK4AOSpgFI2kzSauXYhcDBwE5UyXS48gDY/rPtmeXPGSOIbS3gL+XzQSM4r9Gy4rsWmCNpahlJGDhEHxERLTBsj9j2Gq0IpFmS5gI9ti8oE5F+A7ydaqh1nTKRCeAg2wuGq8/2zyQ92LDr21RDw7eUCU0PAnuXY1dSDX3/xHZ3E+WX10lUQ9NHUPX2R2NZ8V0C7AbcDfw31TPziIhosSl9fUOPNkvaebD9tq8dl4hihdbV1dW35+nHj/t1VqZFH7q6upgxY0bdYaww0h5LSnssbTK2SWdnZ2dHR8eswY4184z4Ew2fp1P9bKiTqjcVERERy6GZoek3NG6XiUdfHa+AxpKkS4CNBuw+fLCJWBEREXUYzRufHgBWijEF2/vUHcNE09vb25Jh44U93UyftkK9STUiYlw0s/rS1ymvt6SaZT0TuGUcY4oVWHd3a17AlSQcEZNFMz3imxs+P0X1EojrxymeiIiISaWZRPws26c27pD0kYH7IiIiYuSaeaHHgYPsO2iM44iVRHv76IeMF/ZkXYmIiIGW2SOWtB/VQgQbSbq04dAawGDvNI5JoK2tjQ3mzR3VuSvTb4MjIlplqKHp31CttvQcqlWC+v0LuH08g4qIiJgslpmIbd8P3A/s0LpwIiIiJpdmfr60PdUC8jOo1vmdCjxue81xji0iImLCa2ay1jeA/YDfA6sC7wFOG8+gIiIiJotmEjG2/wBMtb3Y9neBPcc3rLElaUNJd9Ydx4pI0lGSDqs7joiIyaqZRPxEWe93gaSTJH2syfMmNEmjeT3oaK4ztRXXiYiIejSTTA6gSryHAh8DXgS8ZTyDGidTJX0LeDnwF+BNgIAzgGcCfwTeZfthSdcAh9m+WdJzgJttb1jWOn4zsHqp7+3AhcCaVG35AdvXNV60nLMPsBbwAuA820eXY+8E5lE9e78R+KDtxZIeA84E9gA+BPy6lJ8NfNr2myW9Cfh+qbcNuNv2xpI2oXp0sC7wBPBe2/dIWrfc6/oltI8OfEOapPeW+3uz7SdH29AREdG8YXu2Zfb0FGA920fb/ngZql7ZbAqcZntL4BGqLxPnUq3GtA1wB/D5JurZFtjX9i5Uv7O+wvZM4CXAgmWcs1253jbAWyXNkjQDmAPsWM5fDOxfyq8G3Gj7JbZ/3VDPrVTv+gbYCbgTmA28jCqRA/wH8GHbHcBhwDfL/lOBU2zPLrF8uzFASYcCrwf2ThKOiGidZmZNvwE4marXtpGkmcAxtt84zrGNtXttLyifO4FNqF7f+auy7xzgoibqucp2/wtN5gPfkTQN+HFD/YOd878Akn4EvILqvd0dwHxJUE2E+3spvxj44cBKbD8l6Y8liW8HfAXYmWom+3WSVqfq8V9U6gRYpfy9B7BFw/41S3mAucCfqZJwTxNtEBERY6SZoemjqP6nfw2A7QWSBq7xuzJY1PB5MfCsIco+xdOjBdMHHHu8/4PtayXtDLwOOFvSV6heeNLfs35P+btvySrooxplOMf2pwe5/kLbiwEkXQE8j2p4/D3AtcBrgR7g/wJnUyXiT5SYHyk97IHagO1tL2zcWRLzHVQ97RcC9w5ybkREjJNmJl312H50wL6BiWVl9CjwsKSdyvYBQH/v+D6q3irAvsuqQNIGwP/Y/hbVUO+2ti+xPbP86V+56lWS1pa0KrA3cD1wNbCvpOeWutYu9S3B9mtKXf1J/Trgo8ANth8E1qF61n2n7X8C90p6a6lziqSXlPOuBD7cEPvMhsvcCrwfuFTS85d1vxERMfaaScR3SXoH1eSkTcv6xL8Z57ha5UDgS5Jup+oRHlP2nwx8QNKtVK/4XJZdgdtKuTlUz2EHcxPVUPPtwA9t32z7buAI4Mpy/auA9ZqI+UaqHvK1Zft24A7b/V+O9gfeLek24C6qSWlQTQqbJel2SXcDhzRWWp5FHwb8tExQi4iIFpjS1zd451bS92wfIOkzVJOHXk01nHoFcOzAIc4YXJk1Pcv2oXXHMha6urr69jz9+FGdO1EXfejq6mLGjBl1h7HCSHssKe2xtMnYJp2dnZ0dHR2zBjs21DPijjJMOQd4JUsu/PBMIIk4IiJiOQ2ViM+geo65MXBzw/4pVM+INx7HuCYM22dTTaiKiIhYylCrL30N+Jqk021/oIUxRURETBrD/nwpSTga9fb2jvpZ78KebqZPax/jiCIiVm6T/p3RMTLd3d2jPjdJOCJiaUnEERERNUoijoiIqFEScYxIe/uSw8sLe0Y/VB0REc29azri39ra2thg3tx/b0/Ul3RERLRKesQRERE1SiKOiIioURJxREREjZKIIyIiapTJWuNE0vpUaxS/iOrd3HvZvm8ZZa+hWgLxybLrONsXj1NcZwOXjVf9ERExMknE4+dc4Au2r5K0OtA7TPn9bd88TJmIiJhgkoiXk6TZwFnAdsBU4CZgP+AZtq8CsP3YKOpdl2oFrPXLro/avl7SUcBGVKtfrQ98DNgeeC3wF+ANtnskfQ54A7Aq8Bvg/bb7BlyjA/gKsDrwEHCQ7b+NNNaIiBi9PCNeTrbnA5cCxwEnAedRJclHJP1I0q2SviRp6jBVnS9pQfmzDnAqcIrt2cBbqIa5+20C7Aa8sVzvl7a3phrafl0p8w3bs21vRZWMX994MUnTgK8D+9ruAL4DfGGUzRAREaOUHvHYOAaYDywE5gH7ADsBLwX+G7gQOIiq57wsSwxNS9oD2EJS/641yxA3wM9Lr/cOql745WX/HcCG5fMrJX0SeCawNnAX8F8N1xOwFXBVucZUIL3hiIgWSyIeG+tQDe9OA6YDDwALbP8JQNKPqYaPh0rEA7UB29te2LizJM1FALZ7JfU0DDn3As+QNB34JjDL9p/LcPb0AfVPAe6yvcMIYoqIiDGWoemxcSZwJHA+cCJV7/hZ5TkvVMPId4+wziuBD/dvSJo5gnP7k+5DpRe97yBlDKwraYdS/zRJW44wxoiIWE5JxMtJ0lygx/YFwAnAbGAX4DDg6jJ8PAX41girngfMknS7pLuBQ5o90fYj5Xp3AldQfTEYWKabKkGfKOk2YAHw8hHGGBERy2lKX1/f8KUiiq6urr49Tz/+39tZ9AG6urqYMWNG3WGsMNIeS0p7LG0ytklnZ2dnR0fHrMGOpUccERFRo0zWaiFJl1D9BrjR4bavqCOeiIioXxJxC9nep+4Ylldvb+8Sw9ELe7qZPq29xogiIlZuGZqOEenu7l5iO0k4ImL5JBFHRETUKIk4IiKiRknEERERNUoijhFpb29nYU/38AUjIqIpScQxIm1tbZmgFRExhpKIIyIiapREHBERUaMk4oiIiBolEUdERNQor7hsgqTLge2BX9t+/TBlrwHWA54EVgFOsf0fo7jmQcAs24eO4JxrgMNs3zzS60VERD3SI27Ol4ADRlB+f9szgR2p1vtdIacZS5padwwREZNdesQNJM0GzgK2A6YCNwFzbF8taddRVLk68DiwuNR/OjAbWBW42PbnG657KrAasAjYvZz//NIb3wS4xPYnS/lXA0dT9bj/CBxs+7EB97If8BlgCvBT24eX/Y8BZwJ7AB+S9HrgjcBTwJW2DxvFfUZExCilR9zA9nzgUuA44CTgPNt3jqKq8yXdDhg41vbisv+ztmcB2wC7SNqm9JYvBD5i+yVUCfLJUn4mMAfYGpgj6UWSngMcAexhe1vgZuDjjReX9HzgRGC3UsdsSXuXw6sBN5ZrdQH7AFva3qbcd0REtFAS8dKOAV4FzKJKxqOxf0ls6wOHSdqg7H+bpFuAW4EtgS0AAX8rXwKw/U/bT5XyV9t+1PZC4G5gA6pn1VsA10taABxY9jeaDVxj+8FS1/nAzuXYYuCH5fOjwELgLElvBp4Y5f1GRMQoZWh6aetQDSlPA6ZTDS2Piu0HS+J9maQ24DBgtu2HJZ1d6h/KoobPi6n+eU0BrrK93yjDWtjfQ7f9lKTtqIbC9wUOpepFR0REi6RHvLQzgSOpepEnLk9Fkp4JvJTqOe6aVEn9UUnPA15bihlYrzwnRtIakob6gvRbYEdJLy7lV5O02YAyN1ENfT+nTMjaD/jVIPGtDqxl+2fAx4CXjPJWIyJilNIjbiBpLtBj+4KSwH4jaTeqiVGbA6tLegB4t+0rhqjqfEn9P18623Znqf9W4B7gz8D1ALa7Jc0Bvi5pVarnw3ssq+LSyz4I+E9Jq5TdRwC/ayjzN0mfAn7J05O1fjJIdWsAP5E0vZT7+CBlIiJiHE3p6+urO4ZYiXR1dfXNmDGj7jBWKF1dXaRNnpb2WFLaY2mTsU06Ozs7Ozo6Zg12LEPTERERNcrQ9ChJugTYaMDuw4cZso6IiFhCEvEo2d6n7hjq0Nvby8Ke7qxJHBExRjI0HSPS3Z0kHBExlpKIIyIiapREHBERUaMk4hiR9vZ2FvZ01x1GRMSEkUQcI9LW1pZnxBERYyiJOCIiokZJxBERETVKIo6IiKhREnFERESNkogjIiJqlFdcjhFJlwPbA7+2/fphyl4DHGb75rK9IXCZ7a3KGsbfArahWprwEWBP24+NX/QgadcS05CxR0TE2EoiHjtfAp4JvH856/kI8D+2twaQJKBnNBVJmgJMsd27nDFFRMQ4SSIeIUmzgbOA7YCpwE3AHNtXl17l8loPuL9/w7aXEce6wAXA84EbgFcBHcDqwBXAjWV7L0mfAmYDqwIX2/58qWNP4KvAE8CvxyD2iIgYoSTiEbI9X9KlwHFUie0823eOoqrzJT1ZPrcD/b3W7wBXStoXuBo4x/bvBzn/88AvbB9fEuq7G45tChxo+7cAkj5r+x+SpgJXS9oG+B3VEPhuwB+AC0dxDxERsZwyWWt0jqHqgc4CThplHfvbnml7JrBX/07bC4CNqYa61wbmS5oxyPmvAL5fzrkceLjh2P39Sbh4m6RbgFuBLYEtgM2Be23/3nYfcN4o7yMiIpZDesSjsw7VEPA0YDrw+FhWXiZm/Qj4kaRequHl3YD3liJ7LfPkyr/jkbQRcBgw2/bDks4uMUdExAogPeLRORM4EjgfOHEsK5a0o6Rnl8/tVL3X+22f1t+Dtv1X4HrgbaXcq4FnL6PKNakS86OSnge8tuy/B9hQ0iZle7+xvI+IiGhOEvEISZoL9Ni+ADgBmC1pN0nXARcBu0t6QNJrRnmJTYBfSbqDaij5ZuCHg5Q7Gni1pDuBtwL/P/CvgYVs31bquYdqctf1Zf9C4H3AT8uw9d9HGW9ERCyHDE2PkO1zgXPL58XAy8qhX4ygjl0HbN8HbDWw/mE8CrzG9lOSdqAael4E/LuuhvoPWkYcl1M9K46IiJokEa+81gd+IKkN6Obp58cREbESSSIeR5IuATYasPtw21csb93lJ00vXd56IiKiXknE48j2PnXHMNZ6e3tZ2NPN9GntdYcSETEhZLJWjEh3d5JwRMRYSiKOiIioURJxREREjZKIY0Ta29tZ2NNddxgRERNGEnGMSFtbW54RR0SMoSTiiIiIGiURR0RE1CiJOCIiokZJxBERETVKIo6IiKjRpEnEktYsyxN+Y5hy90n6YcP2vpLOHuacXSW9fIjjP5P0rBHGO09Sl6TzR3LeMuo6RtIe5fM1kmYtb50RETE2JtO7po8Frm2ybIekLWzf3WT5XYHHgN8MdtD2Xk3W0+iDwB62HxjFuQOv/7nlrSMiIsbHhErEkmYDZwHbAVOBm4A5wCrA84DLgWZ6g18GPgvsP6D+tYHvABsDTwDvA/4JHAIslvRO4MO2rxtw3n3luqsDPwd+Dbwc+AvwJttPDih/RrnGzyV9B7geOBWYDjwJHGzbkg4C9gZWAzYFTgbagQOARcBetv9RevSX2b644RrvArax/dGy/V5gC9sfa6J9IiJijEyooWnb84FLgeOAk4DzgLupEuthI6jqB8C2kl48YP/RwK22twE+A5xr+z7gDOAU2zMHJuFBbAqcZntL4BHgLYPcxyHAX4FX2j4FuAfYyfZLgc8BX2wovhXwZmA28AXgiVLuBmDuMPf4BknTyvbBVF8yIiKihSZUIi6OAV5F1QM9iWqI92cjHOJdDHwJ+PSA/a8Avgdg+xfAOpLWHGF899peUD53Ahs2cc5awEWS7gROAbZsOPZL2/+y/SDwKPBfZf8dQ9Vt+zHgF8DrJW0OTLN9xwjuIyIixsCEGpou1qEaAp5GNZS7A7CTpA+W/e2SHrP9qWHq+R5VIr5zJBeXNJUqwQJcOsjz2UUNnxcDq0p6EU8n0DNsnzHgnGOpEu4+kjYErllGfb0N270M/8/321Q9+3uA7w5TNiIixsFETMRnAkcCGwEn2v73c97yTHVWE0kY2z2STgE+RdVzBLiO6rnxsZJ2BR6y/U9J/wLWLOctBmaOJGDbfx7mnLWonicDHDSSuoe57o3lS8C2wDZjVW9ERDRvQg1NS5oL9Ni+ADgBmC1pt+Wo8iyW/LJyFNWM6ttL/QeW/f8F7CNpgaSdluN6y3IScLykWxn7L08/AK63/fAY1xsREU2Y0tfXV3cMUSNJl1FNNLu6mfJdXV19M2bMGOeoVi5dXV2kTZ6W9lhS2mNpk7FNOjs7Ozs6Ogb91c5EHJqOJpQXjNwE3NZsEo6IiLE3aROxpBupfl/c6IDJMnPY9iPAZnXHEREx2U3aRGz7ZXXHsDLq7e1lYU8306e11x1KRMSEMKEma8X46+5OEo6IGEuZrBUj0tnZ+SBwf91xRESsZDbo6OhYd7ADScQRERE1ytB0REREjZKIIyIiapREHBERUaMk4oiIiBolEUdERNQoiTgiIqJGk/bNWjE0SXsCpwJTgW/bPmHA8VWAc4EO4H+BObbva3WcrdJEe+wMfJVqOcm327645UG2WBNt8nHgPcBTwIPAu2xP2N+gN9EehwAfolqH/DHgfbbvbnmgLTJcezSUewtwMTDb9s0tDHGFkR5xLEXSVOA04LXAFsB+krYYUOzdwMO2XwycApzY2ihbp8n2+G+qtaIvaG109WiyTW6lWv97G6r/0Z7U2ihbp8n2uMD21rZnUrXFV1obZes02R5IWgP4CHBjayNcsSQRx2C2A/5g+0+2u4HvA28aUOZNwDnl88XA7pKmtDDGVhq2PWzfZ/t2oLeOAGvQTJv80vYTZfO3wAtbHGMrNdMe/2zYXA2YyG9Taub/IQDHUn2JX9jK4FY0ScQxmBcAf27YfqDsG7SM7aeAR4F1WhJd6zXTHpPNSNvk3cDPxzWiejXVHpI+JOmPVD3ieS2KrQ7DtoekbYEX2f5pKwNbESURR8S4kvROYBbwpbpjqZvt02xvAhwOHFF3PHWR1EY1NP9/6o5lRZBEHIP5C/Cihu0Xln2DlpH0DGAtqklbE1Ez7THZNNUmkvYAPgu80faiFsVWh5H+O/J9YO/xDKhmw7XHGsBWwDWS7gO2By6VNKtlEa5AMms6BjMf2FTSRlT/8bwdeMeAMpcCBwI3APsCv7A9UZ95NdMek82wbSLppcCZwJ62/976EFuqmfbY1Pbvy+brgN8zcQ3ZHrYfBZ7Tvy3pGuCwzJqOKMoz30OBK4Au4Ae275J0jKQ3lmJnAetI+gPwceBT9UQ7/pppD0mzJT0AvBU4U9Jd9UU8/pr8d+RLwOrARZIWSLq0pnDHXZPtcaikuyQtoPpv5sB6oh1/TbZHFFkGMSIiokbpEUdERNQoiTgiIqJGScQRERE1SiKOiIioURJxREREjZKII2LcSPpNi6+3oaTJ/hvvWMkkEUfEuLH98lZdq7zhbUPyspVYyeR3xBExbiQ9Znt1SbsCRwOPAFsDPwDuoFoCb1Vgb9t/lHQ21Uo8s4A1gY/bvkzSdOD0sv+psv+Xkg4C3kz14pCpwCrADOBeqtXBLgG+R7XaEcChtn9T4jkKeIjqVYudwDtt90maTbWO7mrAImB34AngBGDXco3TbJ85tq0Vk1V6xBHRKi8BDqFKlAcAm9neDvg28OGGchtSLaP3OuCMkoQ/BPTZ3hrYDzin7AfYFtjX9i5Ub3i7zvZM26cAfwdeZXtbYA7wtYbrvBT4KNV6uRsDO0pqBy4EPmL7JcAewJNUq0c9ans2MBt4b3l9Y8RySyKOiFaZb/tvZfGHPwJXlv13UCXffj+w3Vvey/wnYHPgFcB5ALbvAe4HNivlr7L9j2VccxrwLUl3ABdRJd1+N9l+wHYvsKDEIOBvtueXa/2zvK7x1cDc8nrKG6mW/Nx0NI0QMVAWfYiIVmlcfam3YbuXJf9fNPB52XDPzx4f4tjHgP+h6o23seQC9I3xLGbo/x9OAT5s+4phYokYsfSII2JF81ZJbZI2oRoyNnAdsD+ApM2A9cv+gf5FtcRev7Woeri9VMPhU4e5toH1ynNiJK1RJoFdAXxA0rT+GCStNkQ9EU1LIo6IFc1/AzcBPwcOsb0Q+CbQVoaYLwQOWsb6xrcDiyXdJulj5bwDJd1GNcQ9VO8Z291Uz5K/Xs65CphO9Rz7buAWSXdSLe+YEcUYE5k1HRErjDJr+jLbF9cdS0SrpEccERFRo/SIIyIiapQecURERI2SiCMiImqURBwREVGjJOKIiIgaJRFHRETU6P8BejDVIbdtSLkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=feat_df.importance[:10] ,y=feat_df.feature[:10], color=dlsu_green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5aa5a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap\n",
      "  Downloading shap-0.40.0.tar.gz (371 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m371.7/371.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/python/3.10.4/lib/python3.10/site-packages (from shap) (1.8.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/python/3.10.4/lib/python3.10/site-packages (from shap) (1.1.1)\n",
      "Collecting tqdm>4.25.0\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>20.9 in /opt/python/3.10.4/lib/python3.10/site-packages (from shap) (21.3)\n",
      "Collecting cloudpickle\n",
      "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
      "Collecting numba\n",
      "  Downloading numba-0.55.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/python/3.10.4/lib/python3.10/site-packages (from shap) (1.4.2)\n",
      "Requirement already satisfied: numpy in /opt/python/3.10.4/lib/python3.10/site-packages (from shap) (1.22.4)\n",
      "Collecting slicer==0.0.7\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/python/3.10.4/lib/python3.10/site-packages (from packaging>20.9->shap) (3.0.9)\n",
      "Collecting llvmlite<0.39,>=0.38.0rc1\n",
      "  Downloading llvmlite-0.38.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m174.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/python/3.10.4/lib/python3.10/site-packages (from numba->shap) (61.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/python/3.10.4/lib/python3.10/site-packages (from pandas->shap) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/python/3.10.4/lib/python3.10/site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/python/3.10.4/lib/python3.10/site-packages (from scikit-learn->shap) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/python/3.10.4/lib/python3.10/site-packages (from scikit-learn->shap) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/python/3.10.4/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n",
      "Building wheels for collected packages: shap\n",
      "  Building wheel for shap (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for shap: filename=shap-0.40.0-cp310-cp310-linux_x86_64.whl size=564016 sha256=49ef8a82a2d9338bf5de24bc1d5e0f88f0f487f0e6ceff0b20fc01ac0d5f974a\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/33/28/e3/62a9dc612c58c1b8d1c16fa51e64941bbb38ac8a6decbad39c\n",
      "Successfully built shap\n",
      "Installing collected packages: tqdm, slicer, llvmlite, cloudpickle, numba, shap\n",
      "\u001b[33m  WARNING: The script tqdm is installed in '/opt/python/3.10.4/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed cloudpickle-2.1.0 llvmlite-0.38.1 numba-0.55.2 shap-0.40.0 slicer-0.0.7 tqdm-4.64.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c0e0579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  0%|                                                                                                                                                                                   | 0/250 [00:00<?, ?it/s]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  0%|▋                                                                                                                                                                          | 1/250 [00:03<13:32,  3.26s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  1%|█▎                                                                                                                                                                         | 2/250 [00:06<12:55,  3.13s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  1%|██                                                                                                                                                                         | 3/250 [00:09<12:35,  3.06s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  2%|██▋                                                                                                                                                                        | 4/250 [00:12<12:27,  3.04s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  2%|███▍                                                                                                                                                                       | 5/250 [00:15<12:10,  2.98s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  2%|████                                                                                                                                                                       | 6/250 [00:18<12:06,  2.98s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  3%|████▊                                                                                                                                                                      | 7/250 [00:21<11:57,  2.95s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  3%|█████▍                                                                                                                                                                     | 8/250 [00:23<11:49,  2.93s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  4%|██████▏                                                                                                                                                                    | 9/250 [00:26<11:52,  2.96s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  4%|██████▊                                                                                                                                                                   | 10/250 [00:29<11:49,  2.96s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  4%|███████▍                                                                                                                                                                  | 11/250 [00:32<11:53,  2.98s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  5%|████████▏                                                                                                                                                                 | 12/250 [00:36<12:09,  3.07s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  5%|████████▊                                                                                                                                                                 | 13/250 [00:39<12:11,  3.09s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  6%|█████████▌                                                                                                                                                                | 14/250 [00:42<11:53,  3.02s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  6%|██████████▏                                                                                                                                                               | 15/250 [00:45<11:37,  2.97s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  6%|██████████▉                                                                                                                                                               | 16/250 [00:47<11:31,  2.96s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  7%|███████████▌                                                                                                                                                              | 17/250 [00:50<11:19,  2.91s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  7%|████████████▏                                                                                                                                                             | 18/250 [00:53<11:15,  2.91s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  8%|████████████▉                                                                                                                                                             | 19/250 [00:56<11:18,  2.94s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  8%|█████████████▌                                                                                                                                                            | 20/250 [00:59<11:16,  2.94s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  8%|██████████████▎                                                                                                                                                           | 21/250 [01:02<11:11,  2.93s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  9%|██████████████▉                                                                                                                                                           | 22/250 [01:05<11:04,  2.91s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  9%|███████████████▋                                                                                                                                                          | 23/250 [01:08<11:02,  2.92s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 10%|████████████████▎                                                                                                                                                         | 24/250 [01:11<10:58,  2.92s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 10%|█████████████████                                                                                                                                                         | 25/250 [01:14<10:57,  2.92s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 10%|█████████████████▋                                                                                                                                                        | 26/250 [01:17<11:00,  2.95s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 11%|██████████████████▎                                                                                                                                                       | 27/250 [01:20<10:58,  2.95s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 11%|███████████████████                                                                                                                                                       | 28/250 [01:23<10:51,  2.94s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 12%|███████████████████▋                                                                                                                                                      | 29/250 [01:25<10:48,  2.93s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 12%|████████████████████▍                                                                                                                                                     | 30/250 [01:28<10:43,  2.93s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 12%|█████████████████████                                                                                                                                                     | 31/250 [01:31<10:43,  2.94s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 13%|█████████████████████▊                                                                                                                                                    | 32/250 [01:34<10:40,  2.94s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 13%|██████████████████████▍                                                                                                                                                   | 33/250 [01:37<10:37,  2.94s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 14%|███████████████████████                                                                                                                                                   | 34/250 [01:40<10:42,  2.98s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 14%|███████████████████████▊                                                                                                                                                  | 35/250 [01:43<10:35,  2.96s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 14%|████████████████████████▍                                                                                                                                                 | 36/250 [01:46<10:32,  2.96s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 15%|█████████████████████████▏                                                                                                                                                | 37/250 [01:49<10:25,  2.94s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 15%|█████████████████████████▊                                                                                                                                                | 38/250 [01:52<10:17,  2.91s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 16%|██████████████████████████▌                                                                                                                                               | 39/250 [01:55<10:16,  2.92s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 16%|███████████████████████████▏                                                                                                                                              | 40/250 [01:58<10:12,  2.92s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 16%|███████████████████████████▉                                                                                                                                              | 41/250 [02:01<10:13,  2.93s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 17%|████████████████████████████▌                                                                                                                                             | 42/250 [02:04<10:09,  2.93s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 17%|█████████████████████████████▏                                                                                                                                            | 43/250 [02:07<10:08,  2.94s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 18%|█████████████████████████████▉                                                                                                                                            | 44/250 [02:10<10:03,  2.93s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 18%|██████████████████████████████▌                                                                                                                                           | 45/250 [02:12<09:56,  2.91s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 18%|███████████████████████████████▎                                                                                                                                          | 46/250 [02:15<09:52,  2.90s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 19%|███████████████████████████████▉                                                                                                                                          | 47/250 [02:18<09:47,  2.89s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 19%|████████████████████████████████▋                                                                                                                                         | 48/250 [02:21<09:47,  2.91s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 20%|█████████████████████████████████▎                                                                                                                                        | 49/250 [02:24<09:47,  2.92s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 20%|██████████████████████████████████                                                                                                                                        | 50/250 [02:27<09:40,  2.90s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 20%|██████████████████████████████████▋                                                                                                                                       | 51/250 [02:30<09:44,  2.94s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 21%|███████████████████████████████████▎                                                                                                                                      | 52/250 [02:33<09:37,  2.92s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 21%|████████████████████████████████████                                                                                                                                      | 53/250 [02:36<09:30,  2.90s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 22%|████████████████████████████████████▋                                                                                                                                     | 54/250 [02:39<09:25,  2.89s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 22%|█████████████████████████████████████▍                                                                                                                                    | 55/250 [02:41<09:24,  2.90s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 22%|██████████████████████████████████████                                                                                                                                    | 56/250 [02:44<09:19,  2.88s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 23%|██████████████████████████████████████▊                                                                                                                                   | 57/250 [02:47<09:17,  2.89s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 23%|███████████████████████████████████████▍                                                                                                                                  | 58/250 [02:50<09:14,  2.89s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 24%|████████████████████████████████████████                                                                                                                                  | 59/250 [02:53<09:10,  2.88s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 24%|████████████████████████████████████████▊                                                                                                                                 | 60/250 [02:56<09:05,  2.87s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 24%|█████████████████████████████████████████▍                                                                                                                                | 61/250 [02:59<09:00,  2.86s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 25%|██████████████████████████████████████████▏                                                                                                                               | 62/250 [03:02<08:59,  2.87s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 25%|██████████████████████████████████████████▊                                                                                                                               | 63/250 [03:04<08:55,  2.87s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 26%|███████████████████████████████████████████▌                                                                                                                              | 64/250 [03:07<08:54,  2.87s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 26%|████████████████████████████████████████████▏                                                                                                                             | 65/250 [03:10<08:53,  2.88s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 26%|████████████████████████████████████████████▉                                                                                                                             | 66/250 [03:13<08:55,  2.91s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 27%|█████████████████████████████████████████████▌                                                                                                                            | 67/250 [03:16<08:54,  2.92s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 27%|██████████████████████████████████████████████▏                                                                                                                           | 68/250 [03:19<08:48,  2.90s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 28%|██████████████████████████████████████████████▉                                                                                                                           | 69/250 [03:22<08:46,  2.91s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 28%|███████████████████████████████████████████████▌                                                                                                                          | 70/250 [03:25<08:43,  2.91s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 28%|████████████████████████████████████████████████▎                                                                                                                         | 71/250 [03:28<08:40,  2.91s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 29%|████████████████████████████████████████████████▉                                                                                                                         | 72/250 [03:31<08:36,  2.90s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 29%|█████████████████████████████████████████████████▋                                                                                                                        | 73/250 [03:34<08:37,  2.93s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 30%|██████████████████████████████████████████████████▎                                                                                                                       | 74/250 [03:36<08:34,  2.93s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 30%|███████████████████████████████████████████████████                                                                                                                       | 75/250 [03:39<08:34,  2.94s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 30%|███████████████████████████████████████████████████▋                                                                                                                      | 76/250 [03:42<08:31,  2.94s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 31%|████████████████████████████████████████████████████▎                                                                                                                     | 77/250 [03:45<08:29,  2.94s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 31%|█████████████████████████████████████████████████████                                                                                                                     | 78/250 [03:48<08:20,  2.91s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 32%|█████████████████████████████████████████████████████▋                                                                                                                    | 79/250 [03:51<08:16,  2.90s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 32%|██████████████████████████████████████████████████████▍                                                                                                                   | 80/250 [03:54<08:17,  2.93s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 32%|███████████████████████████████████████████████████████                                                                                                                   | 81/250 [03:57<08:15,  2.93s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 33%|███████████████████████████████████████████████████████▊                                                                                                                  | 82/250 [04:00<08:12,  2.93s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 33%|████████████████████████████████████████████████████████▍                                                                                                                 | 83/250 [04:03<08:08,  2.93s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 34%|█████████████████████████████████████████████████████████                                                                                                                 | 84/250 [04:06<08:05,  2.93s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 34%|█████████████████████████████████████████████████████████▊                                                                                                                | 85/250 [04:09<08:02,  2.93s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 34%|██████████████████████████████████████████████████████████▍                                                                                                               | 86/250 [04:12<07:59,  2.92s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 35%|███████████████████████████████████████████████████████████▏                                                                                                              | 87/250 [04:15<08:00,  2.95s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 35%|███████████████████████████████████████████████████████████▊                                                                                                              | 88/250 [04:17<07:53,  2.92s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 36%|████████████████████████████████████████████████████████████▌                                                                                                             | 89/250 [04:20<07:48,  2.91s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 36%|█████████████████████████████████████████████████████████████▏                                                                                                            | 90/250 [04:23<07:49,  2.93s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 36%|█████████████████████████████████████████████████████████████▉                                                                                                            | 91/250 [04:26<07:44,  2.92s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 37%|██████████████████████████████████████████████████████████████▌                                                                                                           | 92/250 [04:29<07:41,  2.92s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 37%|███████████████████████████████████████████████████████████████▏                                                                                                          | 93/250 [04:32<07:37,  2.91s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 38%|███████████████████████████████████████████████████████████████▉                                                                                                          | 94/250 [04:35<07:35,  2.92s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 38%|████████████████████████████████████████████████████████████████▌                                                                                                         | 95/250 [04:38<07:30,  2.91s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 38%|█████████████████████████████████████████████████████████████████▎                                                                                                        | 96/250 [04:41<07:27,  2.90s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 39%|█████████████████████████████████████████████████████████████████▉                                                                                                        | 97/250 [04:44<07:27,  2.93s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 39%|██████████████████████████████████████████████████████████████████▋                                                                                                       | 98/250 [04:47<07:22,  2.91s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 40%|███████████████████████████████████████████████████████████████████▎                                                                                                      | 99/250 [04:49<07:16,  2.89s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 40%|███████████████████████████████████████████████████████████████████▌                                                                                                     | 100/250 [04:52<07:12,  2.89s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 40%|████████████████████████████████████████████████████████████████████▎                                                                                                    | 101/250 [04:55<07:11,  2.90s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 41%|████████████████████████████████████████████████████████████████████▉                                                                                                    | 102/250 [04:58<07:07,  2.89s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 41%|█████████████████████████████████████████████████████████████████████▋                                                                                                   | 103/250 [05:01<07:03,  2.88s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 42%|██████████████████████████████████████████████████████████████████████▎                                                                                                  | 104/250 [05:04<07:01,  2.88s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 42%|██████████████████████████████████████████████████████████████████████▉                                                                                                  | 105/250 [05:07<06:56,  2.87s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 42%|███████████████████████████████████████████████████████████████████████▋                                                                                                 | 106/250 [05:10<06:55,  2.88s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 43%|████████████████████████████████████████████████████████████████████████▎                                                                                                | 107/250 [05:12<06:52,  2.88s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 43%|█████████████████████████████████████████████████████████████████████████                                                                                                | 108/250 [05:15<06:50,  2.89s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 44%|█████████████████████████████████████████████████████████████████████████▋                                                                                               | 109/250 [05:18<06:55,  2.95s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 44%|██████████████████████████████████████████████████████████████████████████▎                                                                                              | 110/250 [05:21<06:49,  2.92s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 44%|███████████████████████████████████████████████████████████████████████████                                                                                              | 111/250 [05:24<06:49,  2.94s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 45%|███████████████████████████████████████████████████████████████████████████▋                                                                                             | 112/250 [05:27<06:47,  2.96s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 45%|████████████████████████████████████████████████████████████████████████████▍                                                                                            | 113/250 [05:30<06:44,  2.95s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 46%|█████████████████████████████████████████████████████████████████████████████                                                                                            | 114/250 [05:33<06:40,  2.94s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 46%|█████████████████████████████████████████████████████████████████████████████▋                                                                                           | 115/250 [05:36<06:39,  2.96s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 46%|██████████████████████████████████████████████████████████████████████████████▍                                                                                          | 116/250 [05:39<06:35,  2.95s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 47%|███████████████████████████████████████████████████████████████████████████████                                                                                          | 117/250 [05:42<06:32,  2.95s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 47%|███████████████████████████████████████████████████████████████████████████████▊                                                                                         | 118/250 [05:45<06:34,  2.99s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 48%|████████████████████████████████████████████████████████████████████████████████▍                                                                                        | 119/250 [05:48<06:33,  3.00s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 48%|█████████████████████████████████████████████████████████████████████████████████                                                                                        | 120/250 [05:51<06:35,  3.04s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 48%|█████████████████████████████████████████████████████████████████████████████████▊                                                                                       | 121/250 [05:54<06:34,  3.06s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 49%|██████████████████████████████████████████████████████████████████████████████████▍                                                                                      | 122/250 [05:58<06:41,  3.14s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 49%|███████████████████████████████████████████████████████████████████████████████████▏                                                                                     | 123/250 [06:01<06:39,  3.14s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 50%|███████████████████████████████████████████████████████████████████████████████████▊                                                                                     | 124/250 [06:04<06:33,  3.12s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 50%|████████████████████████████████████████████████████████████████████████████████████▌                                                                                    | 125/250 [06:07<06:23,  3.07s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 50%|█████████████████████████████████████████████████████████████████████████████████████▏                                                                                   | 126/250 [06:10<06:14,  3.02s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 51%|█████████████████████████████████████████████████████████████████████████████████████▊                                                                                   | 127/250 [06:13<06:09,  3.00s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 51%|██████████████████████████████████████████████████████████████████████████████████████▌                                                                                  | 128/250 [06:16<06:03,  2.98s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 52%|███████████████████████████████████████████████████████████████████████████████████████▏                                                                                 | 129/250 [06:19<06:03,  3.01s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 52%|███████████████████████████████████████████████████████████████████████████████████████▉                                                                                 | 130/250 [06:22<05:59,  2.99s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 52%|████████████████████████████████████████████████████████████████████████████████████████▌                                                                                | 131/250 [06:25<05:54,  2.98s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 53%|█████████████████████████████████████████████████████████████████████████████████████████▏                                                                               | 132/250 [06:28<05:49,  2.97s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 53%|█████████████████████████████████████████████████████████████████████████████████████████▉                                                                               | 133/250 [06:31<05:44,  2.94s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 54%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                                              | 134/250 [06:33<05:42,  2.95s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 54%|███████████████████████████████████████████████████████████████████████████████████████████▎                                                                             | 135/250 [06:36<05:38,  2.94s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 54%|███████████████████████████████████████████████████████████████████████████████████████████▉                                                                             | 136/250 [06:39<05:36,  2.95s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 55%|████████████████████████████████████████████████████████████████████████████████████████████▌                                                                            | 137/250 [06:42<05:31,  2.93s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 55%|█████████████████████████████████████████████████████████████████████████████████████████████▎                                                                           | 138/250 [06:45<05:28,  2.93s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 56%|█████████████████████████████████████████████████████████████████████████████████████████████▉                                                                           | 139/250 [06:48<05:27,  2.95s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 56%|██████████████████████████████████████████████████████████████████████████████████████████████▋                                                                          | 140/250 [06:51<05:25,  2.96s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 56%|███████████████████████████████████████████████████████████████████████████████████████████████▎                                                                         | 141/250 [06:54<05:23,  2.97s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 57%|███████████████████████████████████████████████████████████████████████████████████████████████▉                                                                         | 142/250 [06:57<05:20,  2.97s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 57%|████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                        | 143/250 [07:00<05:18,  2.98s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 58%|█████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                       | 144/250 [07:03<05:13,  2.96s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 58%|██████████████████████████████████████████████████████████████████████████████████████████████████                                                                       | 145/250 [07:06<05:08,  2.94s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 58%|██████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                      | 146/250 [07:09<05:04,  2.93s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 59%|███████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                     | 147/250 [07:12<05:02,  2.94s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 59%|████████████████████████████████████████████████████████████████████████████████████████████████████                                                                     | 148/250 [07:15<05:00,  2.95s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 60%|████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                    | 149/250 [07:18<05:00,  2.98s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                   | 150/250 [07:21<04:58,  2.99s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████                                                                   | 151/250 [07:24<04:54,  2.97s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                  | 152/250 [07:27<04:48,  2.94s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 61%|███████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                 | 153/250 [07:30<04:49,  2.98s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                 | 154/250 [07:33<04:45,  2.97s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                | 155/250 [07:36<04:42,  2.97s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 62%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                               | 156/250 [07:39<04:38,  2.97s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                              | 157/250 [07:42<04:34,  2.96s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                              | 158/250 [07:44<04:31,  2.95s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                             | 159/250 [07:47<04:27,  2.94s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                            | 160/250 [07:50<04:24,  2.94s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                            | 161/250 [07:53<04:21,  2.94s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                           | 162/250 [07:56<04:23,  2.99s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                          | 163/250 [08:00<04:26,  3.07s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 66%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                          | 164/250 [08:03<04:19,  3.02s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                         | 165/250 [08:06<04:15,  3.01s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                        | 166/250 [08:08<04:11,  2.99s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                        | 167/250 [08:12<04:09,  3.01s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                       | 168/250 [08:14<04:05,  2.99s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                      | 169/250 [08:17<04:01,  2.99s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                      | 170/250 [08:20<03:59,  3.00s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                     | 171/250 [08:23<03:56,  3.00s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                    | 172/250 [08:26<03:51,  2.97s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                    | 173/250 [08:29<03:49,  2.98s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                   | 174/250 [08:32<03:45,  2.96s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                  | 175/250 [08:35<03:42,  2.97s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                  | 176/250 [08:38<03:37,  2.94s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                 | 177/250 [08:41<03:35,  2.95s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                | 178/250 [08:44<03:32,  2.95s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                | 179/250 [08:47<03:29,  2.95s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                               | 180/250 [08:50<03:25,  2.94s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                              | 181/250 [08:53<03:24,  2.97s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                              | 182/250 [08:56<03:20,  2.95s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                             | 183/250 [08:59<03:17,  2.95s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 74%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                            | 184/250 [09:02<03:14,  2.95s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                            | 185/250 [09:05<03:10,  2.93s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                           | 186/250 [09:08<03:06,  2.91s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                          | 187/250 [09:10<03:03,  2.91s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                          | 188/250 [09:13<02:59,  2.90s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                         | 189/250 [09:16<02:56,  2.89s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 76%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                        | 190/250 [09:19<02:53,  2.89s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                        | 191/250 [09:22<02:51,  2.91s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                       | 192/250 [09:25<02:48,  2.90s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 77%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                      | 193/250 [09:28<02:45,  2.90s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                     | 194/250 [09:31<02:42,  2.91s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                     | 195/250 [09:34<02:40,  2.91s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 78%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                    | 196/250 [09:37<02:36,  2.91s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                   | 197/250 [09:39<02:34,  2.91s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                   | 198/250 [09:42<02:32,  2.93s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                  | 199/250 [09:45<02:29,  2.93s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                 | 200/250 [09:48<02:25,  2.91s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                 | 201/250 [09:51<02:23,  2.93s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                | 202/250 [09:54<02:21,  2.95s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                               | 203/250 [09:57<02:19,  2.97s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                               | 204/250 [10:00<02:16,  2.98s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                              | 205/250 [10:03<02:16,  3.03s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                             | 206/250 [10:06<02:12,  3.01s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                             | 207/250 [10:09<02:07,  2.97s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                            | 208/250 [10:12<02:06,  3.01s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                           | 209/250 [10:16<02:06,  3.09s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                           | 210/250 [10:19<02:05,  3.13s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                          | 211/250 [10:22<02:04,  3.18s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                         | 212/250 [10:25<02:02,  3.22s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                         | 213/250 [10:29<01:58,  3.19s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                        | 214/250 [10:32<01:59,  3.32s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                       | 215/250 [10:36<01:57,  3.37s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 216/250 [10:39<01:52,  3.31s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 217/250 [10:42<01:47,  3.27s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                     | 218/250 [10:45<01:43,  3.24s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                     | 219/250 [10:48<01:38,  3.18s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 220/250 [10:51<01:35,  3.17s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                   | 221/250 [10:55<01:34,  3.25s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                   | 222/250 [10:58<01:30,  3.22s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                  | 223/250 [11:01<01:26,  3.19s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                 | 224/250 [11:04<01:23,  3.20s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 225/250 [11:08<01:21,  3.26s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 226/250 [11:11<01:17,  3.24s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍               | 227/250 [11:17<01:32,  4.04s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 228/250 [11:24<01:51,  5.05s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊              | 229/250 [11:31<01:55,  5.51s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 92%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍             | 230/250 [11:38<01:57,  5.87s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏            | 231/250 [11:44<01:56,  6.13s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊            | 232/250 [11:51<01:52,  6.23s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 93%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 233/250 [11:57<01:46,  6.26s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏          | 234/250 [12:03<01:40,  6.30s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊          | 235/250 [12:10<01:35,  6.39s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌         | 236/250 [12:16<01:28,  6.35s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏        | 237/250 [12:23<01:23,  6.41s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 238/250 [12:30<01:18,  6.52s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 239/250 [12:36<01:11,  6.49s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 240/250 [12:43<01:05,  6.54s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉      | 241/250 [12:49<00:58,  6.48s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌     | 242/250 [12:55<00:49,  6.23s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎    | 243/250 [13:01<00:44,  6.30s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉    | 244/250 [13:08<00:37,  6.32s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 245/250 [13:14<00:31,  6.35s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎  | 246/250 [13:21<00:25,  6.49s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉  | 247/250 [13:27<00:19,  6.43s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      " 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋ | 248/250 [13:32<00:11,  5.90s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 249/250 [13:35<00:05,  5.16s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [13:38<00:00,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My program took 819.0221889019012 to run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "start_time = time.time()\n",
    "explainer = shap.KernelExplainer(clf_grid.best_estimator_.predict, shap.sample(X_train))\n",
    "shap_values = explainer.shap_values(X_test[:250])\n",
    "\n",
    "print(f\"My program took {time.time() - start_time} to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e54aa401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x684 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap.summary_plot(shap_values, X_test.iloc[:250, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a388b8ab",
   "metadata": {},
   "source": [
    "### Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e66a18d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
